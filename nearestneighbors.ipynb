{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total embeddings processed: (168, 1025)\n",
      "(168, 1025)\n"
     ]
    }
   ],
   "source": [
    "# CONVERT TXT EMBEDDINGS TO NUMPY ARRAYS\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def load_and_save_embeddings(file_path, output_file_name):\n",
    "    embeddings = []\n",
    "    \n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            # Split the line into URL and embeddings\n",
    "            split_line = line.strip().split(',')\n",
    "            \n",
    "            # The first element is the URL, and the rest are the embeddings\n",
    "            url = split_line[0]\n",
    "            embedding_values = split_line[1:]\n",
    "            \n",
    "            try:\n",
    "                # Convert the rest of the line (after URL) into floats\n",
    "                embedding = [float(value) for value in embedding_values]\n",
    "                embeddings.append(embedding)\n",
    "            except ValueError:\n",
    "                print(f\"Skipping invalid line: {line}\")\n",
    "                continue\n",
    "\n",
    "    # Convert the list of embeddings into a NumPy array\n",
    "    embeddings_np = np.array(embeddings)\n",
    "\n",
    "    if embeddings_np.size == 0:\n",
    "        print(\"No valid embeddings found.\")\n",
    "    else:\n",
    "        print(f\"Total embeddings processed: {embeddings_np.shape}\")\n",
    "\n",
    "    # Save the embeddings to a new .npy file\n",
    "    np.save(output_file_name, embeddings_np)\n",
    "\n",
    "    return embeddings_np\n",
    "\n",
    "# Example usage\n",
    "file_path = \"genre_embeddings/one_useful_thing_substack_urls_embeddings.txt\"  # Replace with your actual file path\n",
    "output_file_name = \"genre_embeddings/one_useful_thing_numpy_embeddings\"  # Replace with your desired blog name\n",
    "\n",
    "# Load embeddings, ignore URLs, and save as .npy\n",
    "embeddings_np = load_and_save_embeddings(file_path, output_file_name)\n",
    "\n",
    "# Verify by checking the shape of the saved embeddings\n",
    "print(embeddings_np.shape)  # Should print the shape of the embeddings array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Essay 0: Inferred Tag: Related to essays [1, 50, 32, 31]\n",
      "Essay 1: Inferred Tag: Related to essays [32, 17, 50, 22]\n",
      "Essay 2: Inferred Tag: Related to essays [20, 52, 140, 85]\n",
      "Essay 3: Inferred Tag: Related to essays [83, 84, 107, 78]\n",
      "Essay 4: Inferred Tag: Related to essays [98, 108, 143, 153]\n",
      "Essay 5: Inferred Tag: Related to essays [46, 17, 45, 115]\n",
      "Essay 6: Inferred Tag: Related to essays [85, 14, 23, 30]\n",
      "Essay 7: Inferred Tag: Related to essays [30, 64, 46, 159]\n",
      "Essay 8: Inferred Tag: Related to essays [9, 97, 37, 11]\n",
      "Essay 9: Inferred Tag: Related to essays [11, 46, 38, 78]\n",
      "Essay 10: Inferred Tag: Related to essays [11, 22, 46, 115]\n",
      "Essay 11: Inferred Tag: Related to essays [9, 22, 38, 78]\n",
      "Essay 12: Inferred Tag: Related to essays [13, 38, 9, 22]\n",
      "Essay 13: Inferred Tag: Related to essays [9, 38, 74, 17]\n",
      "Essay 14: Inferred Tag: Related to essays [15, 6, 1, 9]\n",
      "Essay 15: Inferred Tag: Related to essays [62, 78, 64, 9]\n",
      "Essay 16: Inferred Tag: Related to essays [79, 111, 17, 27]\n",
      "Essay 17: Inferred Tag: Related to essays [46, 32, 9, 64]\n",
      "Essay 18: Inferred Tag: Related to essays [19, 141, 98, 42]\n",
      "Essay 19: Inferred Tag: Related to essays [98, 9, 78, 58]\n",
      "Essay 20: Inferred Tag: Related to essays [85, 101, 47, 40]\n",
      "Essay 21: Inferred Tag: Related to essays [22, 32, 31, 59]\n",
      "Essay 22: Inferred Tag: Related to essays [11, 32, 38, 46]\n",
      "Essay 23: Inferred Tag: Related to essays [47, 24, 64, 6]\n",
      "Essay 24: Inferred Tag: Related to essays [28, 32, 30, 38]\n",
      "Essay 25: Inferred Tag: Related to essays [35, 103, 73, 72]\n",
      "Essay 26: Inferred Tag: Related to essays [58, 72, 138, 74]\n",
      "Essay 27: Inferred Tag: Related to essays [115, 37, 22, 46]\n",
      "Essay 28: Inferred Tag: Related to essays [24, 38, 9, 32]\n",
      "Essay 29: Inferred Tag: Related to essays [30, 100, 99, 33]\n",
      "Essay 30: Inferred Tag: Related to essays [64, 100, 32, 7]\n",
      "Essay 31: Inferred Tag: Related to essays [32, 49, 50, 0]\n",
      "Essay 32: Inferred Tag: Related to essays [17, 40, 38, 50]\n",
      "Essay 33: Inferred Tag: Related to essays [34, 29, 93, 79]\n",
      "Essay 34: Inferred Tag: Related to essays [17, 46, 78, 64]\n",
      "Essay 35: Inferred Tag: Related to essays [36, 103, 104, 57]\n",
      "Essay 36: Inferred Tag: Related to essays [57, 58, 104, 72]\n",
      "Essay 37: Inferred Tag: Related to essays [115, 38, 27, 32]\n",
      "Essay 38: Inferred Tag: Related to essays [159, 9, 32, 22]\n",
      "Essay 39: Inferred Tag: Related to essays [40, 32, 17, 1]\n",
      "Essay 40: Inferred Tag: Related to essays [32, 17, 22, 46]\n",
      "Essay 41: Inferred Tag: Related to essays [42, 113, 9, 114]\n",
      "Essay 42: Inferred Tag: Related to essays [38, 92, 100, 9]\n",
      "Essay 43: Inferred Tag: Related to essays [44, 78, 9, 96]\n",
      "Essay 44: Inferred Tag: Related to essays [78, 96, 42, 9]\n",
      "Essay 45: Inferred Tag: Related to essays [46, 115, 97, 63]\n",
      "Essay 46: Inferred Tag: Related to essays [64, 17, 78, 9]\n",
      "Essay 47: Inferred Tag: Related to essays [23, 46, 32, 50]\n",
      "Essay 48: Inferred Tag: Related to essays [58, 64, 138, 46]\n",
      "Essay 49: Inferred Tag: Related to essays [50, 31, 32, 40]\n",
      "Essay 50: Inferred Tag: Related to essays [32, 1, 140, 40]\n",
      "Essay 51: Inferred Tag: Related to essays [52, 97, 64, 53]\n",
      "Essay 52: Inferred Tag: Related to essays [38, 28, 9, 159]\n",
      "Essay 53: Inferred Tag: Related to essays [20, 6, 115, 52]\n",
      "Essay 54: Inferred Tag: Related to essays [55, 32, 24, 112]\n",
      "Essay 55: Inferred Tag: Related to essays [72, 57, 58, 60]\n",
      "Essay 56: Inferred Tag: Related to essays [103, 57, 104, 35]\n",
      "Essay 57: Inferred Tag: Related to essays [104, 58, 36, 72]\n",
      "Essay 58: Inferred Tag: Related to essays [57, 104, 72, 36]\n",
      "Essay 59: Inferred Tag: Related to essays [21, 60, 22, 100]\n",
      "Essay 60: Inferred Tag: Related to essays [55, 58, 72, 57]\n",
      "Essay 61: Inferred Tag: Related to essays [62, 111, 79, 112]\n",
      "Essay 62: Inferred Tag: Related to essays [15, 78, 17, 64]\n",
      "Essay 63: Inferred Tag: Related to essays [64, 46, 45, 115]\n",
      "Essay 64: Inferred Tag: Related to essays [46, 17, 9, 134]\n",
      "Essay 65: Inferred Tag: Related to essays [22, 21, 100, 38]\n",
      "Essay 66: Inferred Tag: Related to essays [151, 159, 38, 22]\n",
      "Essay 67: Inferred Tag: Related to essays [68, 9, 120, 28]\n",
      "Essay 68: Inferred Tag: Related to essays [30, 9, 88, 28]\n",
      "Essay 69: Inferred Tag: Related to essays [70, 111, 64, 132]\n",
      "Essay 70: Inferred Tag: Related to essays [57, 58, 90, 72]\n",
      "Essay 71: Inferred Tag: Related to essays [72, 9, 46, 36]\n",
      "Essay 72: Inferred Tag: Related to essays [58, 57, 104, 55]\n",
      "Essay 73: Inferred Tag: Related to essays [157, 137, 74, 112]\n",
      "Essay 74: Inferred Tag: Related to essays [138, 13, 112, 9]\n",
      "Essay 75: Inferred Tag: Related to essays [76, 92, 156, 100]\n",
      "Essay 76: Inferred Tag: Related to essays [159, 58, 42, 38]\n",
      "Essay 77: Inferred Tag: Related to essays [78, 97, 9, 98]\n",
      "Essay 78: Inferred Tag: Related to essays [46, 84, 98, 9]\n",
      "Essay 79: Inferred Tag: Related to essays [111, 139, 16, 80]\n",
      "Essay 80: Inferred Tag: Related to essays [112, 140, 17, 46]\n",
      "Essay 81: Inferred Tag: Related to essays [82, 101, 111, 79]\n",
      "Essay 82: Inferred Tag: Related to essays [9, 58, 13, 46]\n",
      "Essay 83: Inferred Tag: Related to essays [3, 84, 108, 97]\n",
      "Essay 84: Inferred Tag: Related to essays [78, 98, 129, 90]\n",
      "Essay 85: Inferred Tag: Related to essays [6, 64, 46, 86]\n",
      "Essay 86: Inferred Tag: Related to essays [129, 64, 46, 17]\n",
      "Essay 87: Inferred Tag: Related to essays [120, 88, 9, 28]\n",
      "Essay 88: Inferred Tag: Related to essays [68, 28, 30, 52]\n",
      "Essay 89: Inferred Tag: Related to essays [90, 152, 128, 116]\n",
      "Essay 90: Inferred Tag: Related to essays [117, 57, 129, 58]\n",
      "Essay 91: Inferred Tag: Related to essays [92, 84, 42, 44]\n",
      "Essay 92: Inferred Tag: Related to essays [42, 100, 76, 38]\n",
      "Essay 93: Inferred Tag: Related to essays [94, 84, 33, 34]\n",
      "Essay 94: Inferred Tag: Related to essays [34, 17, 78, 64]\n",
      "Essay 95: Inferred Tag: Related to essays [96, 140, 28, 100]\n",
      "Essay 96: Inferred Tag: Related to essays [9, 58, 100, 90]\n",
      "Essay 97: Inferred Tag: Related to essays [98, 78, 45, 8]\n",
      "Essay 98: Inferred Tag: Related to essays [4, 78, 108, 84]\n",
      "Essay 99: Inferred Tag: Related to essays [100, 29, 133, 9]\n",
      "Essay 100: Inferred Tag: Related to essays [42, 110, 28, 22]\n",
      "Essay 101: Inferred Tag: Related to essays [115, 20, 81, 102]\n",
      "Essay 102: Inferred Tag: Related to essays [46, 38, 159, 17]\n",
      "Essay 103: Inferred Tag: Related to essays [35, 56, 57, 104]\n",
      "Essay 104: Inferred Tag: Related to essays [57, 58, 36, 72]\n",
      "Essay 105: Inferred Tag: Related to essays [25, 108, 107, 4]\n",
      "Essay 106: Inferred Tag: Related to essays [103, 57, 56, 104]\n",
      "Essay 107: Inferred Tag: Related to essays [108, 142, 3, 98]\n",
      "Essay 108: Inferred Tag: Related to essays [153, 129, 4, 98]\n",
      "Essay 109: Inferred Tag: Related to essays [110, 119, 64, 78]\n",
      "Essay 110: Inferred Tag: Related to essays [100, 34, 78, 22]\n",
      "Essay 111: Inferred Tag: Related to essays [139, 79, 16, 112]\n",
      "Essay 112: Inferred Tag: Related to essays [140, 80, 74, 138]\n",
      "Essay 113: Inferred Tag: Related to essays [114, 41, 42, 159]\n",
      "Essay 114: Inferred Tag: Related to essays [42, 159, 9, 46]\n",
      "Essay 115: Inferred Tag: Related to essays [27, 46, 37, 45]\n",
      "Essay 116: Inferred Tag: Related to essays [152, 89, 90, 117]\n",
      "Essay 117: Inferred Tag: Related to essays [90, 129, 84, 153]\n",
      "Essay 118: Inferred Tag: Related to essays [119, 70, 90, 76]\n",
      "Essay 119: Inferred Tag: Related to essays [58, 90, 96, 30]\n",
      "Essay 120: Inferred Tag: Related to essays [87, 9, 46, 97]\n",
      "Essay 121: Inferred Tag: Related to essays [9, 64, 123, 85]\n",
      "Essay 122: Inferred Tag: Related to essays [123, 127, 130, 121]\n",
      "Essay 123: Inferred Tag: Related to essays [58, 80, 32, 102]\n",
      "Essay 124: Inferred Tag: Related to essays [125, 64, 9, 30]\n",
      "Essay 125: Inferred Tag: Related to essays [30, 119, 58, 96]\n",
      "Essay 126: Inferred Tag: Related to essays [29, 64, 99, 9]\n",
      "Essay 127: Inferred Tag: Related to essays [130, 122, 123, 115]\n",
      "Essay 128: Inferred Tag: Related to essays [129, 89, 142, 90]\n",
      "Essay 129: Inferred Tag: Related to essays [153, 108, 90, 86]\n",
      "Essay 130: Inferred Tag: Related to essays [127, 123, 115, 122]\n",
      "Essay 131: Inferred Tag: Related to essays [46, 112, 74, 114]\n",
      "Essay 132: Inferred Tag: Related to essays [69, 47, 112, 9]\n",
      "Essay 133: Inferred Tag: Related to essays [78, 134, 99, 46]\n",
      "Essay 134: Inferred Tag: Related to essays [64, 129, 58, 17]\n",
      "Essay 135: Inferred Tag: Related to essays [136, 140, 78, 13]\n",
      "Essay 136: Inferred Tag: Related to essays [58, 159, 78, 22]\n",
      "Essay 137: Inferred Tag: Related to essays [73, 157, 112, 138]\n",
      "Essay 138: Inferred Tag: Related to essays [74, 112, 58, 9]\n",
      "Essay 139: Inferred Tag: Related to essays [111, 79, 112, 140]\n",
      "Essay 140: Inferred Tag: Related to essays [112, 80, 90, 58]\n",
      "Essay 141: Inferred Tag: Related to essays [19, 18, 22, 115]\n",
      "Essay 142: Inferred Tag: Related to essays [128, 107, 152, 129]\n",
      "Essay 143: Inferred Tag: Related to essays [4, 108, 98, 129]\n",
      "Essay 144: Inferred Tag: Related to essays [138, 103, 57, 112]\n",
      "Essay 145: Inferred Tag: Related to essays [115, 52, 102, 37]\n",
      "Essay 146: Inferred Tag: Related to essays [9, 11, 36, 98]\n",
      "Essay 147: Inferred Tag: Related to essays [148, 100, 124, 62]\n",
      "Essay 148: Inferred Tag: Related to essays [110, 94, 78, 22]\n",
      "Essay 149: Inferred Tag: Related to essays [139, 111, 112, 140]\n",
      "Essay 150: Inferred Tag: Related to essays [151, 138, 76, 140]\n",
      "Essay 151: Inferred Tag: Related to essays [159, 66, 38, 76]\n",
      "Essay 152: Inferred Tag: Related to essays [89, 116, 153, 142]\n",
      "Essay 153: Inferred Tag: Related to essays [129, 108, 90, 98]\n",
      "Essay 154: Inferred Tag: Related to essays [155, 159, 9, 140]\n",
      "Essay 155: Inferred Tag: Related to essays [58, 140, 112, 151]\n",
      "Essay 156: Inferred Tag: Related to essays [142, 75, 97, 84]\n",
      "Essay 157: Inferred Tag: Related to essays [73, 137, 112, 74]\n",
      "Essay 158: Inferred Tag: Related to essays [159, 78, 38, 112]\n",
      "Essay 159: Inferred Tag: Related to essays [38, 46, 78, 9]\n",
      "Essay 160: Inferred Tag: Related to essays [167, 74, 48, 138]\n",
      "Essay 161: Inferred Tag: Related to essays [76, 167, 100, 114]\n",
      "Essay 162: Inferred Tag: Related to essays [9, 11, 98, 92]\n",
      "Essay 163: Inferred Tag: Related to essays [13, 80, 64, 92]\n",
      "Essay 164: Inferred Tag: Related to essays [60, 52, 88, 136]\n",
      "Essay 165: Inferred Tag: Related to essays [151, 98, 148, 36]\n",
      "Essay 166: Inferred Tag: Related to essays [60, 22, 42, 13]\n",
      "Essay 167: Inferred Tag: Related to essays [157, 73, 160, 137]\n"
     ]
    }
   ],
   "source": [
    "# GET INFERRED TAGS THRU RELATED ESSAYS \n",
    "\n",
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Load the embeddings\n",
    "embeddings_np = np.load(\"genre_embeddings/one_useful_thing_numpy_embeddings.npy\")  # Replace with your actual .npy file path\n",
    "\n",
    "# Fit Nearest Neighbors model\n",
    "num_neighbors = 5\n",
    "neighbors_model = NearestNeighbors(n_neighbors=num_neighbors, metric='cosine')\n",
    "neighbors_model.fit(embeddings_np)\n",
    "\n",
    "# Propagate inferred tags based purely on neighbors (no pre-assigned tags)\n",
    "def propagate_inferred_tags(embeddings_np):\n",
    "    inferred_tags = {}\n",
    "    \n",
    "    for i in range(len(embeddings_np)):\n",
    "        distances, indices = neighbors_model.kneighbors([embeddings_np[i]])\n",
    "        \n",
    "        # Infer tags based on neighbors' proximity (can be expanded with more logic later)\n",
    "        similar_essays = indices[0][1:]  # Skip the essay itself (first neighbor is itself)\n",
    "        \n",
    "        # For now, let's assign a general \"Related to Essays [X, Y, Z]\" tag for similar essays\n",
    "        inferred_tags[i] = f\"Related to essays {list(similar_essays)}\"\n",
    "    \n",
    "    return inferred_tags\n",
    "\n",
    "# Get the inferred tags for all essays\n",
    "inferred_tags = propagate_inferred_tags(embeddings_np)\n",
    "\n",
    "# Output the results\n",
    "for essay_idx, tag in inferred_tags.items():\n",
    "    print(f\"Essay {essay_idx}: Inferred Tag: {tag}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Essay 0: Tags - Claude 3.5 Sonnet, inference compute, AI scaling\n",
      "Essay 288: Tags - Biotech, Innovation, Healthcare\n",
      "Essay 289: Tags - Climate Change, Policy, Energy\n",
      "Essay 290: Tags - AI Fine-Tuning, Tech Trends, Innovation\n",
      "Essay 291: Tags - Space Exploration, Astrophysics, Engineering\n"
     ]
    }
   ],
   "source": [
    "# Example manual tags for 5 essays\n",
    "manual_tags = {\n",
    "    0: [\"Claude 3.5 Sonnet\", \"inference compute\", \"AI scaling\"],\n",
    "    288: [\"Biotech\", \"Innovation\", \"Healthcare\"],\n",
    "    289: [\"Climate Change\", \"Policy\", \"Energy\"],\n",
    "    290: [\"AI Fine-Tuning\", \"Tech Trends\", \"Innovation\"],\n",
    "    291: [\"Space Exploration\", \"Astrophysics\", \"Engineering\"]\n",
    "}\n",
    "\n",
    "# Print the manually assigned tags\n",
    "for essay_idx, tags in manual_tags.items():\n",
    "    print(f\"Essay {essay_idx}: Tags - {', '.join(tags)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'genre_embeddings/your_embeddings.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/vd/0fxjv75164j7121l38h_z_ym0000gn/T/ipykernel_79110/2118585253.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Load the embeddings from the .npy file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0membeddings_np\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"genre_embeddings/your_embeddings.npy\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Replace with your actual .npy file path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Function to load URLs from the .txt file (with both URLs and embeddings)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    415\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 417\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    418\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'genre_embeddings/your_embeddings.npy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load the embeddings from the .npy file\n",
    "embeddings_np = np.load(\"genre_embeddings/your_embeddings.npy\")  # Replace with your actual .npy file path\n",
    "\n",
    "# Function to load URLs from the .txt file (with both URLs and embeddings)\n",
    "def load_urls(file_path):\n",
    "    urls = []\n",
    "    \n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            if line.startswith('http'):  # Only capture the URL lines\n",
    "                url = line.strip()\n",
    "                urls.append(url)\n",
    "    \n",
    "    return urls\n",
    "\n",
    "# Load the URLs from the .txt file\n",
    "urls = load_urls(\"your_urls_and_embeddings.txt\")  # Replace with your actual .txt file path\n",
    "\n",
    "# Ensure the number of embeddings matches the number of URLs\n",
    "if len(embeddings_np) != len(urls):\n",
    "    print(\"Warning: The number of embeddings does not match the number of URLs!\")\n",
    "else:\n",
    "    print(f\"Loaded {len(urls)} URLs and {len(embeddings_np)} embeddings.\")\n",
    "\n",
    "# Now, each embedding in the NumPy array corresponds to a URL from the .txt file\n",
    "for i, url in enumerate(urls):\n",
    "    print(f\"Embedding {i} corresponds to URL: {url}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: The number of embeddings does not match the number of URLs!\n",
      "Embeddings saved to genre_embeddings/predictive_text_numpy_embeddings.npy\n",
      "URLs saved to genre_embeddings/predictive_text_urls.txt\n"
     ]
    }
   ],
   "source": [
    "# CONVERT TXT EMBEDDINGS TO NUMPY ARRAYS AND MAP TO URLS\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Function to load URLs and embeddings from the .txt file\n",
    "def load_urls_and_embeddings(file_path):\n",
    "    urls = []\n",
    "    embeddings = []\n",
    "\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            if line.startswith('http'):  # URL line\n",
    "                current_url = line.strip()  # Capture the current URL\n",
    "                urls.append(current_url)\n",
    "            else:\n",
    "                # This is an embedding line, so process it\n",
    "                embedding_str = line.strip().split(',')\n",
    "                embedding = np.array([float(val) for val in embedding_str])\n",
    "                embeddings.append(embedding)\n",
    "\n",
    "    return urls, np.array(embeddings)\n",
    "\n",
    "# Function to save the embeddings to a .npy file and URLs to a .txt file\n",
    "def save_embeddings_and_urls(embeddings, urls, npy_file_path, url_file_path):\n",
    "    # Save the embeddings to a .npy file\n",
    "    np.save(npy_file_path, embeddings)\n",
    "    print(f\"Embeddings saved to {npy_file_path}\")\n",
    "\n",
    "    # Save the URLs to a .txt file\n",
    "    with open(url_file_path, 'w') as f:\n",
    "        for url in urls:\n",
    "            f.write(url + '\\n')\n",
    "    print(f\"URLs saved to {url_file_path}\")\n",
    "\n",
    "# Main function to transform .txt into .npy with URL mapping\n",
    "def process_txt_to_npy(txt_file_path, npy_file_path, url_file_path):\n",
    "    # Load the URLs and embeddings from the .txt file\n",
    "    urls, embeddings = load_urls_and_embeddings(txt_file_path)\n",
    "\n",
    "    # Ensure the number of URLs matches the number of embeddings\n",
    "    if len(embeddings) != len(urls):\n",
    "        print(\"Warning: The number of embeddings does not match the number of URLs!\")\n",
    "    else:\n",
    "        print(f\"Loaded {len(urls)} URLs and {len(embeddings)} embeddings.\")\n",
    "\n",
    "    # Save the embeddings and URLs\n",
    "    save_embeddings_and_urls(embeddings, urls, npy_file_path, url_file_path)\n",
    "\n",
    "# Example usage\n",
    "txt_file_path = \"genre_embeddings/predictive_text_substack_urls_embeddings.txt\"  # Replace with your actual .txt file path\n",
    "npy_file_path = \"genre_embeddings/predictive_text_numpy_embeddings.npy\"  # Output file for NumPy array\n",
    "url_file_path = \"genre_embeddings/predictive_text_urls.txt\"        # Output file for the URLs\n",
    "\n",
    "# Run the process\n",
    "process_txt_to_npy(txt_file_path, npy_file_path, url_file_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Load the embeddings from the .npy file\n",
    "embeddings_np = np.load(\"genre_embeddings/predictive_text_numpy_embeddings.npy\")  # Replace with your actual .npy file path\n",
    "\n",
    "# Load the URLs from the .txt file\n",
    "def load_urls(file_path):\n",
    "    urls = []\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            urls.append(line.strip())  # Clean and add URL from the .txt file\n",
    "    return urls\n",
    "\n",
    "urls = load_urls(\"genre_embeddings/predictive_text_urls.txt\")  # Replace with your actual .txt file path\n",
    "\n",
    "# Fit the Nearest Neighbors model on the embeddings\n",
    "num_neighbors = 5  # Adjust as needed\n",
    "neighbors_model = NearestNeighbors(n_neighbors=num_neighbors, metric='cosine')\n",
    "neighbors_model.fit(embeddings_np)\n",
    "\n",
    "# Function to find similar essays for a given essay index and print the URLs\n",
    "def find_similar_essays(essay_index, embeddings_np, urls):\n",
    "    # Wrap the single embedding in double brackets to make it 2D\n",
    "    distances, indices = neighbors_model.kneighbors([embeddings_np[essay_index]])  # Make 2D by adding []\n",
    "\n",
    "    print(f\"Top {num_neighbors} similar essays for essay at URL: {urls[essay_index]}\")\n",
    "    for i, idx in enumerate(indices[0]):\n",
    "        if idx != essay_index:  # Skip the essay itself\n",
    "            print(f\"URL: {urls[idx]} with similarity score: {1 - distances[0][i]:.4f}\")\n",
    "\n",
    "# Example: Find similar essays for essay at index 0\n",
    "find_similar_essays(0, embeddings_np, urls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embeddings shape: (0,)\n"
     ]
    }
   ],
   "source": [
    "embeddings_np = np.load(\"genre_embeddings/predictive_text_numpy_embeddings.npy\")\n",
    "print(f\"Embeddings shape: {embeddings_np.shape}\")  # Should print the shape of the array, expecting (rows, columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function to load URLs and embeddings from the .txt file\n",
    "def load_urls_and_embeddings(file_path):\n",
    "    urls = []\n",
    "    embeddings = []\n",
    "\n",
    "    current_url = None  # Placeholder to track the current URL\n",
    "\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            # Debugging: print the line to see how it's structured\n",
    "            print(f\"Processing line: {line.strip()}\")\n",
    "\n",
    "            # Check if it's a URL line (starts with http or https)\n",
    "            if line.startswith('http'):  # This will now capture both http and https\n",
    "                current_url = line.strip()  # Capture the current URL\n",
    "                print(f\"Found URL: {current_url}\")\n",
    "            else:\n",
    "                # This is an embedding line, process it only if a URL was captured before\n",
    "                if current_url:\n",
    "                    try:\n",
    "                        embedding_str = line.strip().split(',')\n",
    "                        embedding = np.array([float(val) for val in embedding_str])  # Convert each value to float\n",
    "                        embeddings.append(embedding)\n",
    "                        urls.append(current_url)  # Append the current URL for this chunk\n",
    "                        print(f\"Found embedding for URL {current_url}\")\n",
    "                    except ValueError:\n",
    "                        print(f\"Failed to parse embedding line: {line.strip()}\")\n",
    "\n",
    "    return urls, np.array(embeddings)\n",
    "\n",
    "# Load the URLs and embeddings from the .txt file\n",
    "txt_file_path = \"genre_embeddings/predictive_text_substack_urls_embeddings.txt\"  # Replace with your actual .txt file path\n",
    "urls, embeddings = load_urls_and_embeddings(txt_file_path)\n",
    "\n",
    "# Check if embeddings are properly loaded\n",
    "print(f\"Loaded {len(embeddings)} embeddings with shape {embeddings.shape}\")\n",
    "print(f\"Loaded {len(urls)} URLs\")\n",
    "\n",
    "# Save the embeddings to a .npy file\n",
    "npy_file_path = \"genre_embeddings/predictive_text_numpy_embeddings.npy\"  # Path to save NumPy array\n",
    "np.save(npy_file_path, embeddings)\n",
    "print(f\"Embeddings saved to {npy_file_path}\")\n",
    "\n",
    "# Save the URLs to a separate .txt file (with repeated URLs if there are multiple embeddings per URL)\n",
    "url_file_path = \"genre_embeddings/predictive_text_numpy_urls.txt\"  # Path to save URLs\n",
    "with open(url_file_path, 'w') as f:\n",
    "    for url in urls:\n",
    "        f.write(url + '\\n')\n",
    "print(f\"URLs saved to {url_file_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function to load URLs and embeddings from the .txt file\n",
    "def load_urls_and_embeddings(file_path):\n",
    "    urls = []\n",
    "    embeddings = []\n",
    "    current_url = None  # Placeholder to track the current URL\n",
    "\n",
    "    with open(file_path, 'r') as f:\n",
    "        for line in f:\n",
    "            # Debugging: print the line to see how it's structured\n",
    "            print(f\"Processing line: {line.strip()}\")\n",
    "\n",
    "            # Check if it's a URL line (starts with http or https)\n",
    "            if line.startswith('http'):  # This will now capture both http and https\n",
    "                current_url = line.strip()  # Capture the current URL\n",
    "                print(f\"Found URL: {current_url}\")\n",
    "            else:\n",
    "                # Attempt to process this line as an embedding line\n",
    "                print(f\"Processing potential embedding line: {line.strip()}\")\n",
    "                if current_url:\n",
    "                    try:\n",
    "                        embedding_str = line.strip().split(',')\n",
    "                        embedding = np.array([float(val) for val in embedding_str])  # Convert each value to float\n",
    "                        embeddings.append(embedding)\n",
    "                        urls.append(current_url)  # Append the current URL for this chunk\n",
    "                        print(f\"Found embedding for URL {current_url}\")\n",
    "                    except ValueError:\n",
    "                        print(f\"Failed to parse embedding line: {line.strip()}\")\n",
    "\n",
    "    return urls, np.array(embeddings)\n",
    "\n",
    "# Load the URLs and embeddings from the .txt file\n",
    "txt_file_path = \"genre_embeddings/predictive_text_substack_urls_embeddings.txt\"  # Replace with your actual .txt file path\n",
    "urls, embeddings = load_urls_and_embeddings(txt_file_path)\n",
    "\n",
    "# Check if embeddings are properly loaded\n",
    "print(f\"Loaded {len(embeddings)} embeddings with shape {embeddings.shape}\")\n",
    "print(f\"Loaded {len(urls)} URLs\")\n",
    "\n",
    "# Save the embeddings to a .npy file\n",
    "npy_file_path = \"genre_embeddings/predictive_text_numpy_embeddings.npy\"  # Path to save NumPy array\n",
    "np.save(npy_file_path, embeddings)\n",
    "print(f\"Embeddings saved to {npy_file_path}\")\n",
    "\n",
    "# Save the URLs to a separate .txt file (with repeated URLs if there are multiple embeddings per URL)\n",
    "url_file_path = \"genre_embeddings/predictive_text_numpy_urls.txt\"  # Path to save URLs\n",
    "with open(url_file_path, 'w') as f:\n",
    "    for url in urls:\n",
    "        f.write(url + '\\n')\n",
    "print(f\"URLs saved to {url_file_path}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
